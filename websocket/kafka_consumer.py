import asyncio
import json
import logging
import os
import uuid
import time
from collections import OrderedDict
from aiokafka import AIOKafkaConsumer
from core.websocket.websocket_manager import manager

logger = logging.getLogger(__name__)

# Dedupe ìºì‹œ (LRU)
recent_events: OrderedDict[str, float] = OrderedDict()
MAX_CACHE_SIZE = 10000
CACHE_TTL = 300  # 5ë¶„ (ì´ˆ)

async def consume_realtime_events():
    """
    Kafka realtime.events í† í”½ êµ¬ë… ë° WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸
    
    HPA ëŒ€ì‘:
    - group_idë¥¼ uniqueí•˜ê²Œ ì„¤ì • â†’ ëª¨ë“  WS ì¸ìŠ¤í„´ìŠ¤ê°€ ê°™ì€ ë©”ì‹œì§€ ë°›ìŒ
    - ê° ì¸ìŠ¤í„´ìŠ¤ê°€ ìê¸° ì—°ê²° í´ë¼ì´ì–¸íŠ¸ì—ê²Œë§Œ ì „ì†¡
    
    Dedupe:
    - event_id ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µ ë©”ì‹œì§€ í•„í„°ë§
    - LRU ìºì‹œë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬
    """
    # Kafka Consumer ì„¤ì •
    bootstrap_servers = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092")
    unique_group_id = f"websocket-server-{uuid.uuid4().hex[:8]}"
    
    consumer = AIOKafkaConsumer(
        "realtime.events",
        bootstrap_servers=bootstrap_servers,
        group_id=unique_group_id,  # âœ… HPA: ê° ì¸ìŠ¤í„´ìŠ¤ ë‹¤ë¥¸ ID
        value_deserializer=lambda v: json.loads(v.decode('utf-8')),
        auto_offset_reset='latest'
    )
    
    await consumer.start()
    logger.info(f"âœ… Kafka Consumer ì‹œì‘: group_id={unique_group_id}")
    
    try:
        async for msg in consumer:
            try:
                event_data = msg.value
                event_id = event_data.get("event_id")
                
                # Dedupe: ì¤‘ë³µ ì´ë²¤íŠ¸ í•„í„°ë§
                if event_id and event_id in recent_events:
                    logger.debug(f"â­ï¸ ì¤‘ë³µ ì´ë²¤íŠ¸ ë¬´ì‹œ: {event_id}")
                    continue
                
                # ìºì‹œ ì¶”ê°€ (LRU)
                if event_id:
                    recent_events[event_id] = time.time()
                    
                    # ìºì‹œ í¬ê¸° ì œí•œ
                    if len(recent_events) > MAX_CACHE_SIZE:
                        recent_events.popitem(last=False)  # ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì œê±°
                
                # ì±„ë„ ì¶”ì¶œ
                channel = event_data.get("channel", "stock")
                
                # WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸
                await manager.broadcast(channel, event_data)
                
                logger.debug(f"ğŸ“¤ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì™„ë£Œ: channel={channel}, event_id={event_id}")
                
            except Exception as e:
                logger.error(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
    
    except Exception as e:
        logger.error(f"âŒ Kafka Consumer ì—ëŸ¬: {e}", exc_info=True)
    
    finally:
        await consumer.stop()
        logger.info("Kafka Consumer ì¢…ë£Œ")
