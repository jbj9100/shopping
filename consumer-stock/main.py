import asyncio
import os
import logging
import json
import uuid
from dotenv import load_dotenv
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from aiokafka.errors import KafkaError
from db.conn_db import get_db, ping_db, dispose_engine
from repositories.rep_stock_history import create_stock_history_idempotent

load_dotenv()

# ë¡œê¹… ì„¤ì •
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
LOG_FORMAT = os.getenv("LOG_FORMAT", "%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format=LOG_FORMAT
)
logger = logging.getLogger(__name__)


class StockConsumer:
    """ì¬ê³  ì´ë²¤íŠ¸ Consumer - StockHistory ê¸°ë¡ + realtime ì¬ë°œí–‰"""
    
    def __init__(self):
        self.consumer: AIOKafkaConsumer = None
        self.producer: AIOKafkaProducer = None  # realtime ì¬ë°œí–‰ìš©
        
    async def init_consumer(self):
        """Kafka Consumer ì´ˆê¸°í™”"""
        bootstrap_servers = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092").split(",")
        
        self.consumer = AIOKafkaConsumer(
            os.getenv("CONSUMER_TOPIC", "product-events"),
            bootstrap_servers=bootstrap_servers,
            group_id=os.getenv("CONSUMER_GROUP_ID", "stock-consumer-group"),
            enable_auto_commit=False,  # âœ… ìˆ˜ë™ ì»¤ë°‹ (ì„±ê³µ ì‹œì—ë§Œ)
            auto_offset_reset='earliest',  # ì²˜ìŒ ì‹œì‘ ì‹œ ëª¨ë“  ë©”ì‹œì§€ ì½ê¸°
            value_deserializer=lambda v: json.loads(v.decode('utf-8')),
            security_protocol=os.getenv("KAFKA_SECURITY_PROTOCOL", "SASL_PLAINTEXT"),
            sasl_mechanism=os.getenv("KAFKA_SASL_MECHANISM", "PLAIN"),
            sasl_plain_username=os.getenv("KAFKA_USER"),
            sasl_plain_password=os.getenv("KAFKA_PASSWORD"),
        )
        await self.consumer.start()
        logger.info(f"âœ… Kafka Consumer ì‹œì‘: topic={os.getenv('CONSUMER_TOPIC')}, group_id={os.getenv('CONSUMER_GROUP_ID')}")
        
    async def init_producer(self):
        """Kafka Producer ì´ˆê¸°í™” (realtime ì¬ë°œí–‰ìš©)"""
        bootstrap_servers = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092").split(",")
        
        self.producer = AIOKafkaProducer(
            bootstrap_servers=bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            security_protocol=os.getenv("KAFKA_SECURITY_PROTOCOL", "SASL_PLAINTEXT"),
            sasl_mechanism=os.getenv("KAFKA_SASL_MECHANISM", "PLAIN"),
            sasl_plain_username=os.getenv("KAFKA_USER"),
            sasl_plain_password=os.getenv("KAFKA_PASSWORD"),
        )
        await self.producer.start()
        logger.info(f"âœ… Kafka Producer ì‹œì‘: realtime_topic={os.getenv('REALTIME_TOPIC')}")
    
    async def process_event(self, msg):
        """
        ë‹¨ì¼ ì´ë²¤íŠ¸ ì²˜ë¦¬ (ë©±ë“±ì„± + íŠ¸ëœì­ì…˜)
        
        ì²˜ë¦¬ ìˆœì„œ:
        1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
        2. DB íŠ¸ëœì­ì…˜: StockHistory ê¸°ë¡
        3. realtime-eventsë¡œ ì¬ë°œí–‰ (DB ì»¤ë°‹ í›„)
        """
        event_data = msg.value
        
        try:
            # 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
            event_id = event_data.get("event_id")
            if not event_id:
                logger.warning(f"âš ï¸ event_id ì—†ìŒ, ìŠ¤í‚µ: {event_data}")
                # TODO: DLQ í† í”½ìœ¼ë¡œ ì „ì†¡
                return
            
            product_id = event_data.get("product_id")
            if not product_id:
                logger.warning(f"âš ï¸ product_id ì—†ìŒ, ìŠ¤í‚µ: {event_data}")
                return
            
            # 2. DB íŠ¸ëœì­ì…˜: StockHistory ê¸°ë¡
            async for db in get_db():
                # delta ê³„ì‚° (payloadì— ì—†ìœ¼ë©´ ìë™ ê³„ì‚°)
                old_stock = event_data.get("old_stock", 0)
                new_stock = event_data.get("new_stock", 0)
                delta = event_data.get("delta")
                
                # ë””ë²„ê¹…: delta ê³„ì‚° í™•ì¸
                logger.info(f"ğŸ” ë°›ì€ payload delta: {delta}, old_stock: {old_stock}, new_stock: {new_stock}")
                
                if delta is None:
                    delta = new_stock - old_stock  # ìë™ ê³„ì‚°
                    logger.info(f"ğŸ” delta ìë™ ê³„ì‚°: {delta}")
                else:
                    logger.info(f"ğŸ” delta payloadì— í¬í•¨ë¨: {delta}")
                
                history = await create_stock_history_idempotent(
                    db=db,
                    event_id=uuid.UUID(event_id),
                    product_id=product_id,
                    order_id=event_data.get("order_id"),
                    reason=event_data.get("change_reason", "UNKNOWN"),
                    stock_before=old_stock,
                    stock_after=new_stock,
                    delta=delta
                )
                
                if history is None:
                    logger.info(f"â­ï¸ ì¤‘ë³µ ì´ë²¤íŠ¸ ë¬´ì‹œ: {event_id}")
                    return  # ì´ë¯¸ ì²˜ë¦¬ë¨, offsetì€ ì»¤ë°‹í•´ì•¼ ë‹¤ì‹œ ì•ˆ ì½ìŒ
                
                await db.commit()  # âœ… DB ë¨¼ì € ì»¤ë°‹
                logger.info(f"âœ… StockHistory ê¸°ë¡ ì™„ë£Œ: event_id={event_id}, product_id={product_id}")
            
            # 3. realtime-eventsë¡œ ì¬ë°œí–‰ (DB ì»¤ë°‹ í›„)
            try:
                realtime_payload = {
                    "event_id": event_id,
                    "channel": "stock",  # ëª¨ë“  ì¬ê³  ì´ë²¤íŠ¸ëŠ” stock ì±„ë„ë¡œ
                    "type": "STOCK_UPDATED",
                    "data": {
                        "product_id": product_id,
                        "new_stock": event_data.get("new_stock", 0),
                        "is_out_of_stock": event_data.get("is_out_of_stock", False)
                    },
                    "timestamp": event_data.get("timestamp")
                }
                
                await self.producer.send_and_wait(
                    topic=os.getenv("REALTIME_TOPIC", "realtime-events"),
                    value=realtime_payload
                )
                logger.info(f"ğŸ“¤ realtime ì¬ë°œí–‰ ì™„ë£Œ: event_id={event_id}")
                
            except KafkaError as e:
                # realtime ë°œí–‰ ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ (ìµœì¢… ì •í•©ì„± í—ˆìš©)
                logger.error(f"âŒ realtime ë°œí–‰ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
            
        except Exception as e:
            logger.error(f"âŒ ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
            raise  # ì‹¤íŒ¨ ì‹œ offset ì»¤ë°‹ ì•ˆ í•¨ â†’ ì¬ì²˜ë¦¬
    
    async def consume_loop(self):
        """ë©”ì¸ ì†Œë¹„ ë£¨í”„"""
        logger.info("ğŸš€ Stock Consumer ë©”ì¸ ë£¨í”„ ì‹œì‘")
        
        try:
            async for msg in self.consumer:
                try:
                    await self.process_event(msg)
                    
                    # âœ… ì„±ê³µ ì‹œì—ë§Œ offset ì»¤ë°‹
                    await self.consumer.commit()
                    
                except Exception as e:
                    logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨, offset ì»¤ë°‹ ì•ˆ í•¨: {e}")
                    # offset ì»¤ë°‹ ì•ˆ í•˜ë©´ ì¬ì‹œì‘ ì‹œ ë‹¤ì‹œ ì²˜ë¦¬ë¨
                    
        except KeyboardInterrupt:
            logger.info("Consumer ì¢…ë£Œ ì¤‘...")
        finally:
            await self.consumer.stop()
            await self.producer.stop()
            logger.info("Kafka Consumer/Producer ì¢…ë£Œ ì™„ë£Œ")
    
    async def run(self):
        """Consumer ì‹¤í–‰"""
        try:
            # 1. DB ì—°ê²° í…ŒìŠ¤íŠ¸
            logger.info("PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸...")
            success, error = await ping_db()
            if not success:
                raise Exception(f"DB ì—°ê²° ì‹¤íŒ¨: {error}")
            logger.info("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
            
            # 2. Kafka Consumer ì´ˆê¸°í™”
            await self.init_consumer()
            
            # 3. Kafka Producer ì´ˆê¸°í™” (realtimeìš©)
            await self.init_producer()
            
            # 4. ë©”ì¸ ë£¨í”„ ì‹¤í–‰
            await self.consume_loop()
            
        except KeyboardInterrupt:
            logger.info("Stock Consumer ì¢…ë£Œ ì¤‘...")
        except Exception as e:
            logger.error(f"âŒ Consumer ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {type(e).__name__}: {str(e)}")
            raise
        finally:
            # ì •ë¦¬
            await dispose_engine()
            logger.info("Stock Consumer ì™„ì „ ì¢…ë£Œ")


async def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    consumer = StockConsumer()
    await consumer.run()


if __name__ == "__main__":
    asyncio.run(main())
